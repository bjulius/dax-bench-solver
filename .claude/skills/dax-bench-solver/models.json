{
  "models": [
    {
      "id": "anthropic/claude-opus-4.5",
      "name": "Claude Opus 4.5",
      "tier": "frontier",
      "provider": "Anthropic",
      "inputCostPer1M": 5.0,
      "outputCostPer1M": 25.0,
      "contextWindow": 200000,
      "daxBenchRank": 6,
      "daxBenchScore": 78.7
    },
    {
      "id": "anthropic/claude-sonnet-4",
      "name": "Claude Sonnet 4",
      "tier": "strong",
      "provider": "Anthropic",
      "inputCostPer1M": 3.0,
      "outputCostPer1M": 15.0,
      "contextWindow": 1000000,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "anthropic/claude-3.5-sonnet",
      "name": "Claude Sonnet 3.5",
      "tier": "strong",
      "provider": "Anthropic",
      "inputCostPer1M": 6.0,
      "outputCostPer1M": 30.0,
      "contextWindow": 200000,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "openai/gpt-4o",
      "name": "GPT-4o",
      "tier": "frontier",
      "provider": "Openai",
      "inputCostPer1M": 2.5,
      "outputCostPer1M": 10.0,
      "contextWindow": 128000,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "openai/gpt-4-turbo",
      "name": "GPT-4 Turbo",
      "tier": "frontier",
      "provider": "Openai",
      "inputCostPer1M": 10.0,
      "outputCostPer1M": 30.0,
      "contextWindow": 128000,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "google/gemini-2.5-flash",
      "name": "Gemini 2.5 Flash",
      "tier": "efficient",
      "provider": "Google",
      "inputCostPer1M": 0.3,
      "outputCostPer1M": 2.5,
      "contextWindow": 1048576,
      "daxBenchRank": 4,
      "daxBenchScore": 79.7
    },
    {
      "id": "google/gemini-2.5-pro",
      "name": "Gemini 2.5 Pro",
      "tier": "frontier",
      "provider": "Google",
      "inputCostPer1M": 1.25,
      "outputCostPer1M": 10.0,
      "contextWindow": 1048576,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "google/gemini-2.0-flash-lite-001",
      "name": "Gemini 2.0 Flash",
      "tier": "efficient",
      "provider": "Google",
      "inputCostPer1M": 0.075,
      "outputCostPer1M": 0.3,
      "contextWindow": 1048576,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "deepseek/deepseek-chat",
      "name": "DeepSeek V3",
      "tier": "strong",
      "provider": "Deepseek",
      "inputCostPer1M": 0.3,
      "outputCostPer1M": 1.2,
      "contextWindow": 163840,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "qwen/qwen-2.5-coder-32b-instruct",
      "name": "Qwen Coder",
      "tier": "efficient",
      "provider": "Qwen",
      "inputCostPer1M": 0.03,
      "outputCostPer1M": 0.11,
      "contextWindow": 32768,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "meta-llama/llama-3.3-70b-instruct",
      "name": "Llama 3.3 70B",
      "tier": "efficient",
      "provider": "Meta-Llama",
      "inputCostPer1M": 0.1,
      "outputCostPer1M": 0.32,
      "contextWindow": 131072,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "mistralai/mistral-large",
      "name": "Mistral Large",
      "tier": "strong",
      "provider": "Mistralai",
      "inputCostPer1M": 2.0,
      "outputCostPer1M": 6.0,
      "contextWindow": 128000,
      "daxBenchRank": null,
      "daxBenchScore": null
    },
    {
      "id": "mistralai/devstral-small",
      "name": "Devstral",
      "tier": "small",
      "provider": "Mistralai",
      "inputCostPer1M": 0.07,
      "outputCostPer1M": 0.28,
      "contextWindow": 128000,
      "daxBenchRank": null,
      "daxBenchScore": null,
      "note": "Mistral's dedicated coding model"
    }
  ],
  "settings": {
    "maxIterations": 10,
    "timeoutPerAttemptMs": 60000,
    "openRouterBaseUrl": "https://openrouter.ai/api/v1",
    "apiKeyEnvVars": [
      "OPENROUTER_DAXBENCH_API_KEY",
      "OPENROUTER_API_KEY"
    ],
    "apiKeyNote": "Will check env vars in order, using first one found"
  },
  "tiers": {
    "frontier": "Largest, most capable models - highest accuracy, highest cost",
    "strong": "Excellent performance, more cost-effective than frontier",
    "efficient": "Good performance at low cost, may need more iterations",
    "small": "Smallest/cheapest, tests the limits of iteration approach"
  },
  "_lastUpdated": "2025-12-13T15:49:06.629335"
}