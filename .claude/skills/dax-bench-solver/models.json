{
  "models": [
    {
      "id": "anthropic/claude-opus-4-5-20251101",
      "name": "Claude Opus 4.5",
      "tier": "frontier",
      "provider": "Anthropic",
      "inputCostPer1M": 15.00,
      "outputCostPer1M": 75.00,
      "contextWindow": 200000,
      "daxBenchRank": 6,
      "daxBenchScore": 78.7
    },
    {
      "id": "openai/gpt-5.2-chat",
      "name": "GPT-5.2",
      "tier": "frontier",
      "provider": "OpenAI",
      "inputCostPer1M": 10.00,
      "outputCostPer1M": 30.00,
      "contextWindow": 128000,
      "daxBenchRank": 3,
      "daxBenchScore": 79.9
    },
    {
      "id": "google/gemini-3-pro-preview",
      "name": "Gemini 3 Pro",
      "tier": "frontier",
      "provider": "Google",
      "inputCostPer1M": 7.00,
      "outputCostPer1M": 21.00,
      "contextWindow": 1000000,
      "daxBenchRank": 7,
      "daxBenchScore": 77.9
    },
    {
      "id": "openai/gpt-oss-120b",
      "name": "GPT-OSS-120B",
      "tier": "strong",
      "provider": "OpenAI",
      "inputCostPer1M": 2.00,
      "outputCostPer1M": 6.00,
      "contextWindow": 128000,
      "daxBenchRank": 1,
      "daxBenchScore": 81.6
    },
    {
      "id": "deepseek/deepseek-v3.2",
      "name": "DeepSeek V3.2",
      "tier": "strong",
      "provider": "DeepSeek",
      "inputCostPer1M": 0.27,
      "outputCostPer1M": 1.10,
      "contextWindow": 128000,
      "daxBenchRank": 5,
      "daxBenchScore": 79.4
    },
    {
      "id": "anthropic/claude-sonnet-4-5-20250929",
      "name": "Claude Sonnet 4.5",
      "tier": "strong",
      "provider": "Anthropic",
      "inputCostPer1M": 3.00,
      "outputCostPer1M": 15.00,
      "contextWindow": 200000,
      "daxBenchRank": 8,
      "daxBenchScore": 77.5
    },
    {
      "id": "google/gemini-2.5-flash-preview",
      "name": "Gemini 2.5 Flash",
      "tier": "efficient",
      "provider": "Google",
      "inputCostPer1M": 0.15,
      "outputCostPer1M": 0.60,
      "contextWindow": 1000000,
      "daxBenchRank": 4,
      "daxBenchScore": 79.7
    },
    {
      "id": "x-ai/grok-code-fast-1",
      "name": "Grok Code Fast",
      "tier": "efficient",
      "provider": "xAI",
      "inputCostPer1M": 0.30,
      "outputCostPer1M": 0.90,
      "contextWindow": 131072,
      "daxBenchRank": null,
      "daxBenchScore": null,
      "note": "OpenRouter #1 by volume for coding"
    },
    {
      "id": "qwen/qwen3-coder-480b-a35b",
      "name": "Qwen3 Coder",
      "tier": "efficient",
      "provider": "Alibaba",
      "inputCostPer1M": 0.20,
      "outputCostPer1M": 0.60,
      "contextWindow": 131072,
      "daxBenchRank": null,
      "daxBenchScore": null,
      "note": "Rising open-source coding model"
    },
    {
      "id": "mistralai/devstral-2512",
      "name": "Devstral",
      "tier": "small",
      "provider": "Mistral",
      "inputCostPer1M": 0.10,
      "outputCostPer1M": 0.30,
      "contextWindow": 128000,
      "daxBenchRank": null,
      "daxBenchScore": null,
      "note": "Mistral's dedicated coding model"
    }
  ],
  "settings": {
    "maxIterations": 10,
    "timeoutPerAttemptMs": 60000,
    "openRouterBaseUrl": "https://openrouter.ai/api/v1",
    "apiKeyEnvVars": ["OPENROUTER_DAXBENCH_API_KEY", "OPENROUTER_API_KEY"],
    "apiKeyNote": "Will check env vars in order, using first one found"
  },
  "tiers": {
    "frontier": "Largest, most capable models - highest accuracy, highest cost",
    "strong": "Excellent performance, more cost-effective than frontier",
    "efficient": "Good performance at low cost, may need more iterations",
    "small": "Smallest/cheapest, tests the limits of iteration approach"
  }
}
